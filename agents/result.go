// Copyright 2025 The NLP Odyssey Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package agents

import (
	"context"
	"errors"
	"fmt"
	"log/slog"
	"slices"
	"sync/atomic"

	"github.com/nlpodyssey/openai-agents-go/asyncqueue"
	"github.com/nlpodyssey/openai-agents-go/asynctask"
)

type RunResult struct {
	// The original input items i.e. the items before Run() was called. This may be a mutated
	// version of the input, if there are handoff input filters that mutate the input.
	Input Input

	// The new items generated during the agent run.
	//These include things like new messages, tool calls and their outputs, etc.
	NewItems []RunItem

	// The raw LLM responses generated by the model during the agent run.
	RawResponses []ModelResponse

	// The output of the last agent.
	FinalOutput any

	// Guardrail results for the input messages.
	InputGuardrailResults []InputGuardrailResult

	// Guardrail results for the final output of the agent.
	OutputGuardrailResults []OutputGuardrailResult

	// The LastAgent that was run.
	LastAgent *Agent
}

func (r RunResult) String() string {
	return PrettyPrintResult(r)
}

// ToInputList creates a new input list, merging the original input with all the new items generated.
func (r RunResult) ToInputList() []TResponseInputItem {
	return toInputList(r.Input, r.NewItems)
}

// LastResponseID is a convenience method to get the response ID of the last model response.
func (r RunResult) LastResponseID() string {
	return lastResponseID(r.RawResponses)
}

// RunResultStreaming is the result of an agent run in streaming mode.
// You can use the `StreamEvents` method to receive semantic events as they are generated.
//
// The streaming method will return the following errors:
// - A MaxTurnsExceededError if the agent exceeds the max_turns limit.
// - A *GuardrailTripwireTriggeredError error if a guardrail is tripped.
type RunResultStreaming struct {
	// The original input items i.e. the items before Run() was called. This may be a mutated
	// version of the input, if there are handoff input filters that mutate the input.
	Input Input

	// The new items generated during the agent run.
	//These include things like new messages, tool calls and their outputs, etc.
	NewItems []RunItem

	// The raw LLM responses generated by the model during the agent run.
	RawResponses []ModelResponse

	// The output of the last agent.
	FinalOutput any

	// Guardrail results for the input messages.
	InputGuardrailResults []InputGuardrailResult

	// Guardrail results for the final output of the agent.
	OutputGuardrailResults []OutputGuardrailResult

	context context.Context

	// The current agent that is running.
	CurrentAgent *Agent

	// The current turn number.
	CurrentTurn *atomic.Uint64

	// The maximum number of turns the agent can run for.
	MaxTurns uint64

	// optional
	currentAgentOutputSchema AgentOutputSchemaInterface

	// Whether the agent has finished running.
	IsComplete *atomic.Bool

	// Queues that the background run-loop writes to.
	eventQueue          *asyncqueue.Queue[StreamEvent]
	inputGuardrailQueue *asyncqueue.Queue[InputGuardrailResult]

	runImplTask          *atomic.Pointer[asynctask.Task[error]]
	inputGuardrailsTask  *atomic.Pointer[asynctask.Task[error]]
	outputGuardrailsTask *atomic.Pointer[asynctask.Task[outputGuardrailsTaskResult]]

	storedException error
}

type outputGuardrailsTaskResult struct {
	Result []OutputGuardrailResult
	Err    error
}

// ToInputList creates a new input list, merging the original input with all the new items generated.
func (r *RunResultStreaming) ToInputList() []TResponseInputItem {
	return toInputList(r.Input, r.NewItems)
}

// LastResponseID is a convenience method to get the response ID of the last model response.
func (r *RunResultStreaming) LastResponseID() string {
	return lastResponseID(r.RawResponses)
}

// The LastAgent that was run.
// Updates as the agent run progresses, so the true last agent is only
// available after the agent run is complete.
func (r *RunResultStreaming) LastAgent() *Agent {
	return r.CurrentAgent
}

// Cancel the streaming run, stopping all background tasks and marking the run as complete.
func (r *RunResultStreaming) Cancel() {
	r.cleanupTasks()         // Cancel all running tasks
	r.IsComplete.Store(true) // Mark the run as complete to stop event streaming

	// Optionally, clear the event queue to prevent processing stale events
	for !r.eventQueue.IsEmpty() {
		_, _ = r.eventQueue.GetNoWait()
	}
	for !r.inputGuardrailQueue.IsEmpty() {
		_, _ = r.inputGuardrailQueue.GetNoWait()
	}
}

// StreamEvents streams deltas for new items as they are generated.
// We're using the types from the OpenAI Responses API, so these are semantic events:
// each event has a `Type` field that describes the type of the event, along with the data for that event.
//
// Possible well-known errors returned:
//   - A MaxTurnsExceededError if the agent exceeds the MaxTurns limit.
//   - A *GuardrailTripwireTriggeredError if a guardrail is tripped.
func (r *RunResultStreaming) StreamEvents(fn func(StreamEvent) error) error {
	for {
		err := r.checkErrors()
		if err != nil {
			return err
		}

		if r.storedException != nil {
			slog.Debug("Breaking due to stored exception")
			r.IsComplete.Store(true)
			break
		}

		if r.IsComplete.Load() && r.eventQueue.IsEmpty() {
			break
		}

		item := r.eventQueue.Get()

		if _, ok := item.(queueCompleteSentinel); ok {
			// Check for errors, in case the queue was completed due to an exception
			if err = r.checkErrors(); err != nil {
				return err
			}

			// NOTE: this differs from the original Python implementation.
			// We just reached the end of streaming without errors. However,
			// the asynchronous execution of input guardrails might be slower than
			// everything else. Let's wait for their completion, and check for errors
			// once again, as a tripwire might have been triggered.
			if t := r.inputGuardrailsTask.Load(); t != nil && !t.IsDone() {
				_ = t.Await()
				if err = r.checkErrors(); err != nil {
					return err
				}
			}

			break
		}

		err = fn(item)
		if err != nil {
			return err
		}
	}

	r.cleanupTasks()
	return r.storedException
}

// createErrorDetails returns a RunErrorDetails object considering the current attributes of the class.
func (r *RunResultStreaming) createErrorDetails() *RunErrorDetails {
	return &RunErrorDetails{
		Context:                r.context,
		Input:                  r.Input,
		NewItems:               r.NewItems,
		RawResponses:           r.RawResponses,
		LastAgent:              r.CurrentAgent,
		InputGuardrailResults:  r.InputGuardrailResults,
		OutputGuardrailResults: r.OutputGuardrailResults,
	}
}

func (r *RunResultStreaming) checkErrors() error {
	if r.CurrentTurn.Load() > r.MaxTurns {
		maxTurnsErr := MaxTurnsExceededErrorf("Max turns (%d) exceeded", r.MaxTurns)
		maxTurnsErr.AgentsError.RunData = r.createErrorDetails()
		r.storedException = maxTurnsErr
	}

	// Fetch all the completed guardrail results from the queue and raise if needed
	for !r.inputGuardrailQueue.IsEmpty() {
		guardrailResult, ok := r.inputGuardrailQueue.GetNoWait()
		if ok && guardrailResult.Output.TripwireTriggered {
			tripwireErr := NewInputGuardrailTripwireTriggeredError(guardrailResult)
			tripwireErr.AgentsError.RunData = r.createErrorDetails()
			r.storedException = tripwireErr
		}
	}

	// Check the tasks for any exceptions
	if t := r.runImplTask.Load(); t != nil && t.IsDone() {
		result := t.Await()
		if result.Canceled {
			return NewTaskCanceledError("run task has been canceled")
		}
		if err := *result.Result; err != nil {
			var agentsErr *AgentsError
			if errors.As(err, &agentsErr) && agentsErr.RunData == nil {
				agentsErr.RunData = r.createErrorDetails()
			}
			r.storedException = fmt.Errorf("run-impl task error: %w", err)
		}
	}

	if t := r.inputGuardrailsTask.Load(); t != nil && t.IsDone() {
		result := t.Await()
		if result.Canceled {
			return NewTaskCanceledError("input guardrails task has been canceled")
		}
		if err := *result.Result; err != nil {
			var agentsErr *AgentsError
			if errors.As(err, &agentsErr) && agentsErr.RunData == nil {
				agentsErr.RunData = r.createErrorDetails()
			}
			r.storedException = fmt.Errorf("input guardrails task error: %w", err)
		}
	}

	if t := r.outputGuardrailsTask.Load(); t != nil && t.IsDone() {
		result := t.Await()
		if result.Canceled {
			return NewTaskCanceledError("output guardrails task has been canceled")
		}
		if err := result.Result.Err; err != nil {
			var agentsErr *AgentsError
			if errors.As(err, &agentsErr) && agentsErr.RunData == nil {
				agentsErr.RunData = r.createErrorDetails()
			}
			r.storedException = fmt.Errorf("output guardrails task error: %w", err)
		}
	}

	return nil
}

func (r *RunResultStreaming) cleanupTasks() {
	if t := r.runImplTask.Load(); t != nil && !t.IsDone() {
		t.Cancel()
	}
	if t := r.inputGuardrailsTask.Load(); t != nil && !t.IsDone() {
		t.Cancel()
	}
	if t := r.outputGuardrailsTask.Load(); t != nil && !t.IsDone() {
		t.Cancel()
	}
}

func (r *RunResultStreaming) String() string {
	return PrettyPrintRunResultStreaming(*r)
}

func toInputList(input Input, newRunItems []RunItem) []TResponseInputItem {
	originalItems := ItemHelpers().InputToNewInputList(input)

	result := make([]TResponseInputItem, len(newRunItems))
	for i, item := range newRunItems {
		result[i] = item.ToInputItem()
	}

	return slices.Concat(originalItems, result)
}

func lastResponseID(rawResponses []ModelResponse) string {
	if len(rawResponses) == 0 {
		return ""
	}
	return rawResponses[len(rawResponses)-1].ResponseID
}
