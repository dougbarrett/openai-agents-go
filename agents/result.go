// Copyright 2025 The NLP Odyssey Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package agents

import (
	"fmt"
	"log/slog"
	"slices"

	"github.com/nlpodyssey/openai-agents-go/asyncqueue"
	"github.com/nlpodyssey/openai-agents-go/asynctask"
)

type RunResultBase struct {
	// The original input items i.e. the items before Run() was called. This may be a mutated
	// version of the input, if there are handoff input filters that mutate the input.
	Input Input

	// The new items generated during the agent run.
	//These include things like new messages, tool calls and their outputs, etc.
	NewItems []RunItem

	// The raw LLM responses generated by the model during the agent run.
	RawResponses []ModelResponse

	// The output of the last agent.
	FinalOutput any

	// Guardrail results for the input messages.
	InputGuardrailResults []InputGuardrailResult

	// Guardrail results for the final output of the agent.
	OutputGuardrailResults []OutputGuardrailResult
}

// ToInputList creates a new input list, merging the original input with all the new items generated.
func (r RunResultBase) ToInputList() []TResponseInputItem {
	originalItems := ItemHelpers().InputToNewInputList(r.Input)

	newItems := make([]TResponseInputItem, len(r.NewItems))
	for i, item := range r.NewItems {
		newItems[i] = item.ToInputItem()
	}

	return slices.Concat(originalItems, newItems)
}

// LastResponseID is a convenience method to get the response ID of the last model response.
func (r RunResultBase) LastResponseID() string {
	if len(r.RawResponses) == 0 {
		return ""
	}
	return r.RawResponses[len(r.RawResponses)-1].ResponseID
}

type RunResult struct {
	RunResultBase
	lastAgent *Agent
}

// The LastAgent that was run.
func (r RunResult) LastAgent() *Agent {
	return r.lastAgent
}

func (r RunResult) String() string {
	return PrettyPrintResult(r)
}

// RunResultStreaming is the result of an agent run in streaming mode.
// You can use the `StreamEvents` method to receive semantic events as they are generated.
//
// The streaming method will return the following errors:
// - A MaxTurnsExceededError if the agent exceeds the max_turns limit.
// - A *GuardrailTripwireTriggeredError error if a guardrail is tripped.
type RunResultStreaming struct {
	RunResultBase

	// The current agent that is running.
	CurrentAgent *Agent

	// The current turn number.
	CurrentTurn uint64

	// The maximum number of turns the agent can run for.
	MaxTurns uint64

	// optional
	currentAgentOutputSchema AgentOutputSchemaInterface

	// Whether the agent has finished running.
	IsComplete bool

	// Queues that the background run-loop writes to.
	eventQueue          *asyncqueue.Queue[StreamEvent]
	inputGuardrailQueue *asyncqueue.Queue[InputGuardrailResult]

	runImplTask          *asynctask.Task[error]
	inputGuardrailsTask  *asynctask.Task[error]
	outputGuardrailsTask *asynctask.Task[outputGuardrailsTaskResult]

	storedException error
}

type outputGuardrailsTaskResult struct {
	Result []OutputGuardrailResult
	Err    error
}

// The LastAgent that was run.
// Updates as the agent run progresses, so the true last agent is only
// available after the agent run is complete.
func (r *RunResultStreaming) LastAgent() *Agent {
	return r.CurrentAgent
}

// Cancel the streaming run, stopping all background tasks and marking the run as complete.
func (r *RunResultStreaming) Cancel() {
	r.cleanupTasks()    // Cancel all running tasks
	r.IsComplete = true // Mark the run as complete to stop event streaming

	// Optionally, clear the event queue to prevent processing stale events
	for !r.eventQueue.IsEmpty() {
		_, _ = r.eventQueue.GetNoWait()
	}
	for !r.inputGuardrailQueue.IsEmpty() {
		_, _ = r.inputGuardrailQueue.GetNoWait()
	}
}

// StreamEvents streams deltas for new items as they are generated.
// We're using the types from the OpenAI Responses API, so these are semantic events:
// each event has a `Type` field that describes the type of the event, along with the data for that event.
//
// Possible well-known errors returned:
//   - A MaxTurnsExceededError if the agent exceeds the MaxTurns limit.
//   - A *GuardrailTripwireTriggeredError if a guardrail is tripped.
func (r *RunResultStreaming) StreamEvents(fn func(StreamEvent) error) error {
	for {
		err := r.checkErrors()
		if err != nil {
			return err
		}

		if r.storedException != nil {
			slog.Debug("Breaking due to stored exception")
			r.IsComplete = true
			break
		}

		if r.IsComplete && r.eventQueue.IsEmpty() {
			break
		}

		item := r.eventQueue.Get()

		if _, ok := item.(queueCompleteSentinel); ok {
			// Check for errors, in case the queue was completed due to an exception
			if err = r.checkErrors(); err != nil {
				return err
			}

			// NOTE: this differs from the original Python implementation.
			// We just reached the end of streaming without errors. However,
			// the asynchronous execution of input guardrails might be slower than
			// everything else. Let's wait for their completion, and check for errors
			// once again, as a tripwire might have been triggered.
			if r.inputGuardrailsTask != nil && !r.inputGuardrailsTask.IsDone() {
				_ = r.inputGuardrailsTask.Await()
				if err = r.checkErrors(); err != nil {
					return err
				}
			}

			break
		}

		err = fn(item)
		if err != nil {
			return err
		}
	}

	r.cleanupTasks()
	return r.storedException
}

func (r *RunResultStreaming) checkErrors() error {
	if r.CurrentTurn > r.MaxTurns {
		r.storedException = MaxTurnsExceededErrorf("Max turns (%d) exceeded", r.MaxTurns)
	}

	// Fetch all the completed guardrail results from the queue and raise if needed
	for !r.inputGuardrailQueue.IsEmpty() {
		guardrailResult, ok := r.inputGuardrailQueue.GetNoWait()
		if ok && guardrailResult.Output.TripwireTriggered {
			r.storedException = NewInputGuardrailTripwireTriggeredError(guardrailResult)
		}
	}

	// Check the tasks for any exceptions
	if r.runImplTask != nil && r.runImplTask.IsDone() {
		result := r.runImplTask.Await()
		if result.Canceled {
			return NewCanceledError("run task has been canceled")
		}
		if err := *result.Result; err != nil {
			r.storedException = fmt.Errorf("run-impl task error: %w", err)
		}
	}

	if r.inputGuardrailsTask != nil && r.inputGuardrailsTask.IsDone() {
		result := r.inputGuardrailsTask.Await()
		if result.Canceled {
			return NewCanceledError("input guardrails task has been canceled")
		}
		if err := *result.Result; err != nil {
			r.storedException = fmt.Errorf("input guardrails task error: %w", err)
		}
	}

	if r.outputGuardrailsTask != nil && r.outputGuardrailsTask.IsDone() {
		result := r.outputGuardrailsTask.Await()
		if result.Canceled {
			return NewCanceledError("output guardrails task has been canceled")
		}
		if err := result.Result.Err; err != nil {
			r.storedException = fmt.Errorf("output guardrails task error: %w", err)
		}
	}

	return nil
}

func (r *RunResultStreaming) cleanupTasks() {
	if r.runImplTask != nil && !r.runImplTask.IsDone() {
		r.runImplTask.Cancel()
	}
	if r.inputGuardrailsTask != nil && !r.inputGuardrailsTask.IsDone() {
		r.inputGuardrailsTask.Cancel()
	}
	if r.outputGuardrailsTask != nil && !r.outputGuardrailsTask.IsDone() {
		r.outputGuardrailsTask.Cancel()
	}
}

func (r *RunResultStreaming) String() string {
	return PrettyPrintRunResultStreaming(*r)
}
